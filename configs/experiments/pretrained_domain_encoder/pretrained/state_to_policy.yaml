seed: &seed 0

n_iters_training: 5_000_000
batch_size: &batch_size 2048

log_every: 1_000
eval_every: 5_000
save_every: 5_000

update_encoder_every: &update_encoder_every 5

model:
  _target_: agents.imitation_learning.cross_domain.domain_encoder.OneDomainEncoder.create
  seed: *seed
  encoding_dim: 16
  #
  batch_size: *batch_size
  target_random_buffer_state_path: ._tmp_archive_dir/random_buffers/HalfCheetah-v5.pickle
  source_expert_buffer_state_path: agents/experts/HalfCheetah-v5/config/collected_rollouts/buffer_state.pickle
  #
  update_encoder_every: *update_encoder_every
  #
  target_encoder_config:
    _target_: misc.gan.generator.Generator.create
    module_config:
      _target_: agents.imitation_learning.cross_domain.domain_encoder.networks.MLPSigmoidOnTop
      hidden_dims: [256, 256]
    optimizer_config:
      transforms:
        - _target_: optax.clip
          max_delta: 1.0
        - _target_: optax.adamw
          learning_rate: 3e-4
    loss_config:
      _target_: agents.imitation_learning.cross_domain.domain_encoder.OneDomainEncoderProjectedGradStateToPolicyGradFn
      state_loss_scale: 0.5
  discriminators_config:
    _target_: agents.imitation_learning.cross_domain.domain_encoder.BaseDomainEncoderDiscriminators.create
    state_discriminator_config:
      _target_: misc.gan.discriminator.LoosyDiscriminator.create
      module_config:
        _target_: nn.networks.MLP
        hidden_dims: [256, 256]
        out_dim: 1
        squeeze: True
      optimizer_config:
        transforms:
          - _target_: optax.clip
            max_delta: 1.0
          - _target_: optax.adamw
            learning_rate: 3e-4
      loss_config:
        _target_: misc.gan.losses.SoftplusLoss
        is_generator: False
    policy_discriminator_config:
      _target_: misc.gan.discriminator.LoosyDiscriminator.create
      module_config:
        _target_: nn.networks.MLP
        hidden_dims: [256, 256]
        out_dim: 1
        squeeze: True
      optimizer_config:
        transforms:
          - _target_: optax.clip
            max_delta: 1.0
          - _target_: optax.adamw
            learning_rate: 3e-4
      loss_config:
        _target_: misc.gan.losses.SoftplusLoss
        is_generator: False

