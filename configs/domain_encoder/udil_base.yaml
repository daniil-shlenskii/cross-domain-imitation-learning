_constants:
  encoding_dim: &encoding_dim 16
  update_encoder_every: &update_encoder_every 5
  state_loss_scale: &state_loss_scale 0.5
  target_random_buffer_state_path: &target_random_buffer_path ._tmp_archive_dir/random_buffers/HalfCheetah-v5.pickle
  source_expert_buffer_state_path: &source_expert_buffer_path agents/experts/HalfCheetah-v5/config/collected_rollouts/buffer_state.pickle
  freeze_target_encoder: &freeze_target_encoder True
  use_target_random_batch_for_policy_discrminator: &use_target_random_batch_for_policy_discrminator False

seed: &seed 0

n_iters_training: 2_000_000
batch_size: &batch_size 256

log_every: 500
eval_every: 5_000
save_every: 5_000

model:
  _target_: agents.imitation_learning.cross_domain.domain_encoder.TwoDomainsEncoder.create
  seed: *seed
  encoding_dim: *encoding_dim
  update_encoder_every: *update_encoder_every
  freeze_target_encoder: *freeze_target_encoder
  #
  batch_size: *batch_size
  target_random_buffer_state_path: *target_random_buffer_path
  source_expert_buffer_state_path: *source_expert_buffer_path
  #
  target_encoder_config:
    _target_: misc.gan.generator.Generator.create
    module_config:
      _target_: nn.networks.MLP
      hidden_dims: [256, 256]
    optimizer_config:
      transforms:
        - _target_: optax.clip
          max_delta: 1.0
        - _target_: optax.adamw
          learning_rate: 3e-4
    loss_config:
      _target_: agents.imitation_learning.cross_domain.domain_encoder.BaseTargetDomainEncoderLoss
      target_state_loss_scale: *state_loss_scale
      source_state_loss_scale: *state_loss_scale
  source_encoder_config:
    _target_: misc.gan.generator.Generator.create
    module_config:
      _target_: nn.networks.MLP
      hidden_dims: [256, 256]
    optimizer_config:
      transforms:
        - _target_: optax.clip
          max_delta: 1.0
        - _target_: optax.adamw
          learning_rate: 3e-4
    loss_config:
      _target_: agents.imitation_learning.cross_domain.domain_encoder.UDILSourceDomainEncoderLoss
      target_state_loss_scale: *state_loss_scale
      source_state_loss_scale: *state_loss_scale
  discriminators_config:
    _target_: agents.imitation_learning.cross_domain.domain_encoder.BaseDomainEncoderDiscriminators.create
    update_policy_discriminator_every: *update_encoder_every
    use_target_random_batch_for_policy_discrminator: *use_target_random_batch_for_policy_discrminator
    state_discriminator_config:
      _target_: misc.gan.discriminator.LoosyDiscriminator.create
      module_config:
        _target_: nn.networks.MLP
        hidden_dims: [256, 256]
        out_dim: 1
        squeeze: True
      optimizer_config:
        transforms:
          - _target_: optax.clip
            max_delta: 1.0
          - _target_: optax.adamw
            learning_rate: 3e-4
      loss_config:
        _target_: misc.gan.losses.SoftplusLoss
        is_generator: False
    policy_discriminator_config:
      _target_: misc.gan.discriminator.LoosyDiscriminator.create
      module_config:
        _target_: nn.networks.MLP
        hidden_dims: [256, 256]
        out_dim: 1
        squeeze: True
      optimizer_config:
        transforms:
          - _target_: optax.clip
            max_delta: 1.0
          - _target_: optax.adamw
            learning_rate: 3e-4
      loss_config:
        _target_: misc.gan.losses.SoftplusLoss
        is_generator: False

