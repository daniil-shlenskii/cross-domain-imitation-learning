seed: &seed 42
n_training_iters: 30_000
batch_size: 128
eval_batch_size: 512
log_every: 500
eval_every: 500

dataset:
  size: 20_000
  mu: [1, 2, 4]
  sigma: [1, 1, 3]

gan:
  _target_: misc.gan.GAN.create
  seed: *seed
  loss_config:
    _target_: misc.gan.losses.LogisticLossGP
    gradient_penalty_coef: 2.
  generator_config:
    module_config:
      _target_: nn.networks.MLP
      n_blocks: 2
      hidden_dim: 128
    optimizer_config:
      transforms:
        - _target_: optax.clip
          max_delta: 1.0
        - _target_: optax.adamw
          learning_rate: 3e-4
  discriminator_config:
    module_config:
      _target_: nn.networks.MLP
      n_blocks: 2
      hidden_dim: 128
      out_dim: 1
      squeeze: True
    optimizer_config:
      transforms:
        - _target_: optax.clip
          max_delta: 1.0
        - _target_: optax.adamw
          learning_rate: 3e-4
