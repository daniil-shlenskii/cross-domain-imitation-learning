seed: &seed 2
env_name: &env_name Hopper-v5 # HalfCheetah-v5
precollect_buffer_size: &precollect_buffer_size 5_000
n_iters_training: 50_000
log_every: 500
eval_every: 500

agent:
  _target_: experts.sac_agent.SACAgent
  seed: *seed
  update_temperature: False
  actor_module_config:
    _target_: networks.policy.NormalTanhPolicy
    hidden_dims: [256, 256]
  critic_module_config:
    _target_: networks.critic.Critic
    hidden_dims: [256, 256]
  temperature_module_config:
    _target_: networks.extra.Temperature
    initial_temperature: 0.2
  actor_optimizer_config: &optimizer_config
    transforms:
      - _target_: optax.clip
        max_delta: 1.0
      - _target_: optax.adamw
        learning_rate: 3e-4
  critic_optimizer_config: *optimizer_config
  temperature_optimizer_config: *optimizer_config

environment:
  _target_: gymnasium.wrappers.TimeLimit
  max_episode_steps: 1000
  env:
      _target_: gymnasium.make
      id: *env_name
      render_mode: human

evaluation:
  seed: 0
  num_episodes: 10
  environment:
    _target_: gymnasium.wrappers.TimeLimit
    max_episode_steps: 1000
    env:
        _target_: gymnasium.make
        id: *env_name

replay_buffer:
  _target_: flashbax.make_item_buffer
  max_length: 1_000_000
  min_length: *precollect_buffer_size
  sample_batch_size: 64
  add_batches: False

archive:
  agent_load_dir: &agent_dir archive/agents/sac
  agent_save_dir: *agent_dir
  agent_buffer_load_dir: *agent_dir
  agent_buffer_save_dir: *agent_dir
  random_buffer_load_dir: &random_buffer_dir archive/random_buffers
  random_buffer_save_dir: *random_buffer_dir
